Model Config:
	batch_size = 32
	hidden_size = 128
	dropout = 0.25
	lstm_dropout = 0.0
	alpha = 0.4
	num_epochs = 130
	lr = 0.0005
	weight_decay = 1e-05
	eta_min = 1e-06

Results:
              precision    recall  f1-score   support

           0       0.87      0.90      0.89       326
           1       0.67      0.67      0.67        96
           2       0.31      0.26      0.28        31
           3       0.69      0.64      0.66        88
           4       0.70      0.68      0.69        47

    accuracy                           0.77       588
   macro avg       0.65      0.63      0.64       588
weighted avg       0.77      0.77      0.77       588
