Model Config:
	batch_size = 32
	hidden_size = 128
	dropout = 0.25
	lstm_dropout = 0.0
	alpha = 1.0
	num_epochs = 130
	lr = 0.0005
	weight_decay = 1e-05
	eta_min = 1e-06

Results:
              precision    recall  f1-score   support

           0       0.87      0.87      0.87       326
           1       0.69      0.67      0.68        96
           2       0.38      0.39      0.38        31
           3       0.62      0.66      0.64        88
           4       0.80      0.77      0.78        47

    accuracy                           0.77       588
   macro avg       0.67      0.67      0.67       588
weighted avg       0.77      0.77      0.77       588
