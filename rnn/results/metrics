Model Config:
	batch_size = 32
	hidden_size = 128
	dropout = 0.25
	lstm_dropout = 0.0
	alpha = 1.0
	num_epochs = 130
	lr = 0.0005
	weight_decay = 1e-05
	eta_min = 1e-06

Results:
              precision    recall  f1-score   support

           0       0.85      0.87      0.86       326
           1       0.59      0.59      0.59        96
           2       0.25      0.26      0.25        31
           3       0.73      0.62      0.67        88
           4       0.71      0.77      0.73        47

    accuracy                           0.75       588
   macro avg       0.63      0.62      0.62       588
weighted avg       0.75      0.75      0.75       588
