{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils import data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('data.csv', delimiter=\",\")\n",
    "\n",
    "df = df.drop(['instant', 'dteday', 'casual', 'registered'], axis=1)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = data.TensorDataset(torch.tensor(train.values[:,:-1]), torch.tensor(train.values[:,-1]))\n",
    "test_dataset = data.TensorDataset(torch.tensor(test.values[:,:-1]), torch.tensor(test.values[:,-1]))\n",
    "train_data_loader = data.DataLoader(train_dataset, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Evaluator(nn.Module):\n",
    "\n",
    "    def __init__(self, num_inputs, num_hidden, num_outputs):\n",
    "        super().__init__()\n",
    "        # Initialize the modules we need to build the network\n",
    "        self.linear1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.batch_norm = nn.BatchNorm1d(num_hidden)\n",
    "        self.act_fn = nn.LeakyReLU()\n",
    "        self.linear2 = nn.Linear(num_hidden, num_hidden)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(num_hidden)\n",
    "        self.linear3 = nn.Linear(num_hidden, num_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Perform the calculation of the model to determine the prediction\n",
    "        x = self.linear1(x)\n",
    "        x = self.batch_norm(x)\n",
    "        x = self.act_fn(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.act_fn(x)\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 5.03e+04\n",
      "Epoch: 1, loss: 4.86e+04\n",
      "Epoch: 2, loss: 4.57e+04\n",
      "Epoch: 3, loss: 4.19e+04\n",
      "Epoch: 4, loss: 3.76e+04\n",
      "Epoch: 5, loss: 3.33e+04\n",
      "Epoch: 6, loss: 2.86e+04\n",
      "Epoch: 7, loss: 2.45e+04\n",
      "Epoch: 8, loss: 2e+04\n",
      "Epoch: 9, loss: 1.56e+04\n",
      "Epoch: 10, loss: 1.2e+04\n",
      "Epoch: 11, loss: 8.83e+03\n",
      "Epoch: 12, loss: 6.73e+03\n",
      "Epoch: 13, loss: 4.31e+03\n",
      "Epoch: 14, loss: 2.97e+03\n",
      "Epoch: 15, loss: 1.98e+03\n",
      "Epoch: 16, loss: 1.45e+03\n",
      "Epoch: 17, loss: 1.3e+03\n",
      "Epoch: 18, loss: 1.08e+03\n",
      "Epoch: 19, loss: 1.01e+03\n",
      "Epoch: 20, loss: 4.45e+02\n",
      "Epoch: 21, loss: 4.04e+02\n",
      "Epoch: 22, loss: 2.43e+02\n",
      "Epoch: 23, loss: 2.22e+02\n",
      "Epoch: 24, loss: 1.88e+02\n",
      "Epoch: 25, loss: 2.18e+02\n",
      "Epoch: 26, loss: 1.41e+02\n",
      "Epoch: 27, loss: 1.52e+02\n",
      "Epoch: 28, loss: 1.45e+02\n",
      "Epoch: 29, loss: 1.21e+02\n",
      "Epoch: 30, loss: 1.21e+02\n",
      "Epoch: 31, loss: 91.4\n",
      "Epoch: 32, loss: 90.8\n",
      "Epoch: 33, loss: 92.2\n",
      "Epoch: 34, loss: 62.6\n",
      "Epoch: 35, loss: 68.3\n",
      "Epoch: 36, loss: 50.2\n",
      "Epoch: 37, loss: 53.3\n",
      "Epoch: 38, loss: 34.9\n",
      "Epoch: 39, loss: 31.5\n",
      "Epoch: 40, loss: 23.9\n",
      "Epoch: 41, loss: 25.0\n",
      "Epoch: 42, loss: 21.1\n",
      "Epoch: 43, loss: 27.9\n",
      "Epoch: 44, loss: 21.1\n",
      "Epoch: 45, loss: 22.5\n",
      "Epoch: 46, loss: 18.1\n",
      "Epoch: 47, loss: 28.0\n",
      "Epoch: 48, loss: 27.6\n",
      "Epoch: 49, loss: 45.5\n",
      "Epoch: 50, loss: 30.6\n",
      "Epoch: 51, loss: 24.3\n",
      "Epoch: 52, loss: 30.8\n",
      "Epoch: 53, loss: 21.8\n",
      "Epoch: 54, loss: 27.8\n",
      "Epoch: 55, loss: 25.5\n",
      "Epoch: 56, loss: 31.4\n",
      "Epoch: 57, loss: 28.8\n",
      "Epoch: 58, loss: 36.8\n",
      "Epoch: 59, loss: 31.0\n",
      "Epoch: 60, loss: 44.3\n",
      "Epoch: 61, loss: 34.1\n",
      "Epoch: 62, loss: 37.1\n",
      "Epoch: 63, loss: 32.8\n",
      "Epoch: 64, loss: 34.0\n",
      "Epoch: 65, loss: 39.6\n",
      "Epoch: 66, loss: 39.7\n",
      "Epoch: 67, loss: 41.6\n",
      "Epoch: 68, loss: 38.7\n",
      "Epoch: 69, loss: 48.4\n",
      "Epoch: 70, loss: 44.9\n",
      "Epoch: 71, loss: 53.5\n",
      "Epoch: 72, loss: 58.3\n",
      "Epoch: 73, loss: 47.7\n",
      "Epoch: 74, loss: 60.9\n",
      "Epoch: 75, loss: 46.2\n",
      "Epoch: 76, loss: 65.2\n",
      "Epoch: 77, loss: 46.9\n",
      "Epoch: 78, loss: 61.7\n",
      "Epoch: 79, loss: 58.0\n",
      "Epoch: 80, loss: 46.0\n",
      "Epoch: 81, loss: 51.8\n",
      "Epoch: 82, loss: 67.5\n",
      "Epoch: 83, loss: 54.3\n",
      "Epoch: 84, loss: 72.8\n",
      "Epoch: 85, loss: 58.9\n",
      "Epoch: 86, loss: 70.5\n",
      "Epoch: 87, loss: 67.5\n",
      "Epoch: 88, loss: 63.7\n",
      "Epoch: 89, loss: 65.2\n",
      "Epoch: 90, loss: 61.1\n",
      "Epoch: 91, loss: 60.1\n",
      "Epoch: 92, loss: 58.1\n",
      "Epoch: 93, loss: 55.9\n",
      "Epoch: 94, loss: 58.0\n",
      "Epoch: 95, loss: 58.6\n",
      "Epoch: 96, loss: 56.0\n",
      "Epoch: 97, loss: 56.3\n",
      "Epoch: 98, loss: 68.6\n",
      "Epoch: 99, loss: 56.8\n"
     ]
    }
   ],
   "source": [
    "model = Evaluator(num_inputs=12, num_hidden=64, num_outputs=1)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "loss_module = nn.MSELoss()\n",
    "\n",
    "model.train() \n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):\n",
    "    for data_inputs, data_labels in train_data_loader:\n",
    "\n",
    "        ## Step 1: Move input data to device (only strictly necessary if we use GPU)\n",
    "        data_inputs = data_inputs.float().to(device)\n",
    "        data_labels = data_labels.float().to(device)\n",
    "\n",
    "        ## Step 2: Run the model on the input data\n",
    "        preds = model(data_inputs)\n",
    "        preds = preds.squeeze(dim=1) # Output is [Batch size, 1], but we want [Batch size]\n",
    "\n",
    "        ## Step 3: Calculate the loss\n",
    "        loss = loss_module(preds, data_labels)\n",
    "\n",
    "        ## Step 4: Perform backpropagation\n",
    "        # Before calculating the gradients, we need to ensure that they are all zero. \n",
    "        # The gradients would not be overwritten, but actually added to the existing ones.\n",
    "        optimizer.zero_grad() \n",
    "        # Perform backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        ## Step 5: Update the parameters\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch: {epoch}, loss: {loss.item():.3}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss on test data: 0.613\n"
     ]
    }
   ],
   "source": [
    "def rmsle(y_true,y_pred):\n",
    "    n = len(y_true)\n",
    "    msle = np.mean([(np.log(max(y_pred[i],0) + 1) - np.log(y_true[i] + 1)) ** 2.0 for i in range(n)])\n",
    "    return np.sqrt(msle)\n",
    "\n",
    "data_inputs, data_labels = test_dataset.tensors\n",
    "data_inputs = data_inputs.float().to(device)\n",
    "data_labels = data_labels.float().to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    preds = model(data_inputs)\n",
    "    preds = preds.squeeze(dim=1)\n",
    "\n",
    "preds = preds.cpu().numpy()\n",
    "data_labels = data_labels.cpu().numpy()\n",
    "\n",
    "loss = rmsle(data_labels, preds)\n",
    "print(f\"Loss on test data: {loss:.3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = pd.read_csv(\"evaluation_data.csv\", delimiter=\",\")\n",
    "targets = targets.drop(['dteday'], axis=1)\n",
    "inputs = torch.tensor(targets.values, dtype=torch.float32)\n",
    "inputs = inputs.to(device)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(inputs).squeeze()\n",
    "\n",
    "pd.DataFrame(outputs.detach().cpu()).to_csv(\"results.csv\", index=False, header=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
